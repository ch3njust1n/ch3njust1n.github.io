<!DOCTYPE html>
<html>
<header>
    <meta charset="UTF-8">
    <base href="/">
    <title>Justin Chen - CS585</title>
    <link rel='stylesheet' type='text/css' href='css/normalize.css'>
    <link rel='stylesheet' type='text/css' href='css/style.css'>
    <style>
        html {
            font-family: Avenir Next;
        }
        
        body {
            margin-top: 3em;
            height: 100vh;
            width: 100vw;
            -Ibkit-background-size: cover;
            -moz-background-size: cover;
            -o-background-size: cover;
            background-size: cover;
        }
        
        a {
            text-decoration: none;
        }
        
        ul {
            list-style-type: none;
        }
        
        #content {
            min-width: 870px;
            margin: 160px 0px 0px 145px;
            padding: 0%;
        }
        
        #content ul {
            background-color: #A8D6FF;
        }
        
        #content ul li {
            font-size: 3em;
            margin-right: 30px;
            display: inline-block;
        }
        
        #content ul li a {
            color: #FFFFFF;
        }
        
        #content ul li a:hover {
            opacity: 0.5;
        }
        
        #project {
            margin-left: 42px;
            margin-right: 7%;
        }
        
        #project-title {
            font-size: 3em;
        }
        
        .sub-header {
            font-size: 1.5em;
        }

        .caption {
            font-size: 13px;
        }

        .col
        {
            margin-left: 1%;
            width: 32%;
            float:left;
        }

        @media screen and (max-width: 870px) {
            body {
                margin-top: 3em;
                height: 100vh;
                width: 870px;
                -Ibkit-background-size: cover;
                -moz-background-size: cover;
                -o-background-size: cover;
                background-size: cover;
            }

            #content {
                width: 870px;
                margin: 144px 0px 0px 0px;
                padding: 0%;
                overflow: hidden;
                white-space: nowrap;
            }
        }
    </style>
</header>

<body>
    <div id="content">
        <ul>
            <li>
                <a href="/chenjus">HOME</a>
            </li>
            <li>
                |
            </li>
            <li>
                <a href="/chenjus/about">ABOUT</a>
            </li>
            <li>
                |
            </li>
            <li>
                <a href="/chenjus/cs585">CS585</a>
            </li>
        </ul>
        <div id="project">
            <span id="project-title">Assignment 3</span>
            <br>
            <span id="project-description">Justin Chen</span>
            <br>
            <span id="project-description">Date: 10/3/16</span>
            <p>
                <span class="sub-header">Problem Definition</span>
                <br> The goal of this assignment was to design and implement algorithms to identify objects in video images and analyze their orientation, circularity, area, and compactness. To do this the objects of interest needed to be segmented from the image. Typically, the objects of interest were in the foreground of the image. To approach this problem, I assumed the the images given to had a static background which assumed that the images were taken from a stationary camera. However, even with this assumption, segmenting the objects from the images was still difficult. Often, my implementation would also segment out background objects. Although, the problem in itself was relatively straigtfoward, segmentation and delineation are important concepts in computer vision for correctly and accurately capturing and analyzing objects of interest.
            </p>
            <p>
                <span class="sub-header">Method and Implementation</span>
                <br> I chose to use three different methods (absolute thresholding, color range thresholding, and iterative thresholding.) to segment each dataset. After segmentation, each image object in each frame was labeled with a random color. My program runs on one dataset at a time. After starting the program, the user is displayed with a menu with datasets and can then select the dataset which they would like to analyze.
                <br>
                <br> For the normalized cells dataset, I used a combination of background differencing and absolute thresholding to capture the cells in each frame. This approach seemed most intuitive since the cells were actively moving around between frames. Background differencing took the absolute difference between the previous frame and the current frame. Since the color of the background and cells were similar, I set the absolute threshold to be pretty sensitive to change setting it to a low pixel intensity of 10, from the range 0 to 255. This made the cells easy to detect.
                <br>
                <br> Next, I used color range thresholding for the aquarium dataset. The objective was to identify the fish in the video frames. Initially looking at the images, it was even difficult detecting the fish manually, as a human. The fish didn't move around very much and the plants in the background moved with the water current. Background differencing would not have worked very well. The most defining characteristic of each fish, however, was their colors. After trying several ranges of hues and saturations, it seemed that the hue of the fish laid in the range 75 to 115, and the saturation was in the range 92 to 255 and the intensity was in the range 34 to 164. After setting these ranges, the algorithm, cropped the portion of the image that contained mostly background objects and left part of the right side of the image where there were the most notable fish and then segmented this portion of the image.
                <br>
                <br> Finally, I used iterative thresholding for the gray bats dataset. This function uses the average grayscale value as the initial threshold as a lower bound to segment the background and foreground. The average grayscale value is then computed for those foreground values to create a new foreground value, essentially raising the lower bound for foreground objects. This process is repeated until the grayscale value essentially leveled out. This segmentation method worked well for this dataset since the background initally contrasted nicely with the bats. I then cropped the bottom of the frames to remove the landscape that was also being captured.
                <br>
                <br> After segmentation, the inital frame is eroded and dilated to remove noise. A copy of this morphologically altered frame is copied to another matrix, which is then super-dilated to create a frame with blobs of each object. These two frames and a blank frame are then sent to another function to color the initial frame. The function searches the super-dilated frame for white pixels. When it finds one, it assumes that this is a new object, chooses a random color for the label, and performs breadth-first search on the white blob. On each iteration of breadth-first search, it compares the corresponding pixel in the inital frame, with the pixel in the super-dilated frame. If both are white, then it colors the third frame in the corresponding position. In any other case, it assumes the pixels are mismatched and labels them as background. Essentially, this overlays the super-dilated frame over the intial frame and assumes that the blobs in the super-dilated frame cover its corresponding object in the initial frame. The breadth-first search simulataneously collected the label values for each pixel, so that each object could be analyzed.
                <br>
                <br> These labels were used to determine the orientation, circularity, area, and compactness of each object in each frame using standard formulae presented during lecture.
            </p>
            <p>
                <span class="sub-header">Experiments</span>
                <br> After implementing out initial segmentation algorithms, I experimented with adjusting values to increase my accuracy of capturing my objects of interest. This included adjusting the color range, absolute thresholding values and morphological operation parameters.
                <br><br> 
                Cells Dataset Background Differencing with Absolute Thresholding and Morphological Operations Experiments:
                For this experiment, I tested different absolute threshold values until I found a suite value, which I refer to as a catered value. For the high value, I tried a unsigned char of 20. This threshold greatly fragemented the orignal cells. As can be seen from the colored and labeled image, the algorithm identified more objects than there actually were. The low threshold value could not differentiate well between background pixels and the cells and the segmented image ended up with a low of noise, which are the massive pink objects. The catered or middle value, however, reasonably segmented out the cells and did not capture too many background pixels and did not mistake multiple cells for one.
                <br><br>
                Aquarium Dataset: Color Range and Morphological Operations Experiments<br>
                For this experiment, I tested how well the algorithm performed with a wide, catered, and narrow color range. For the wide range, I set used the following ranges: Hue: [0, 255], Saturation: [0, 255], Min/Max: [0, 255]. For the catered range, I used the following ranges: Hue: [75, 115], Saturation: [92, 255], Min/Max: [34, 164]. As for the narrow range, I used the following ranges: Hue: [64, 192], Saturation: [64, 192], Min/Max: [64, 192].
                <br><br>
                Bats Dataset: Morphological Operations Experiment<br>
                The iterative thesholding algorithm's only parameters were the grayscale values of the image, so there were no obvious parameters for the algorithm to manipulate. Instead, I experimented with dilating the image. Eroding the image was not interesting since it would only diminish the shapes of the bats and would not prove much else. Dilating the bats too much caused the labeling algorithm to mistake bats in close proximity to each other to be labeled as one, which can be seen where multiple bats, although not overlapping, are labeled green. Setting the kernel too small caused individual bats to be fragmented and each of its parts being labeled as individual bats. The middle value worked pretty well and reasonably detected individual bats with very little mistake.
                <br><br>
                For these experiments, there were no exact metrics for evaluating accuracy other than looking at the output and manually detected mistakes as the video played.
            </p>
            <p>
                <span class="sub-header">Results</span>
                <br><br>
                <span class="sub-header">Sample Properties Output</span>
                <br>
                <img src="/chenjus/cs585/a3/imgs/sample-property-output.png" height="630" width="1080">
                <br><br>
                <span class="sub-header">Cells Dataset: Background Differencing with Absolute Thresholding and Morphological Operations Experiments</span>
                <div class="col">
                    Segmented
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-seg.png" height="210" width="360">
                    <br> 
                    Erode: 1x1 kernel, Dilate: 1x1 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-morphed.png" height="210" width="360">
                    <br>
                    Labeled/Colored
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-morph-good.png" height="210" width="360">
                    <br>
                </div>
                <div class="col">
                    Threshold: uchar 20
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-abs-high.png" height="210" width="360">
                    <br> 
                    Threshold: uchar 10
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-morph-good.png" height="210" width="360">
                    <br>
                    Threshold: uchar 2
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-abs-low.png" height="210" width="360">
                    <br>
                </div>
                <div class="col">
                    Dilate: 20x20 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-morph-high.png" height="210" width="360">
                    <br> 
                    Dilate: 10x10 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-morph-good.png" height="210" width="360">
                    <br>
                    Dilate: 2x2 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/cell-morph-low.png" height="210" width="360">
                    <br>
                </div>
            </p>
            <p>
                <span class="sub-header">Aquarium Dataset: Color Range and Morphological Operations Experiments</span>
                <div class="col">
                    Segmented Cropped 
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-seg.png" height="210" width="360">
                    <br> 
                    Erode: 1x1 kernel, Dilate: 1x1 kernel Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-morphed.png" height="210" width="360">
                    <br>
                    Labeled/Colored Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-morph-good.png" height="210" width="360">
                    <br>
                    Original Segmented
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-seg.png" height="210" width="360">
                    <br>
                    Original Morphed
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-morphed.png" height="210" width="360">
                    <br>
                    Original Labeled/Colored
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-color.png" height="210" width="360">
                    <br>
                </div>
                <div class="col">
                    Color Range: Wide Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-wide.png" height="210" width="360">
                    <br> 
                    Color Range: Catered Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-morph-good.png" height="210" width="360">
                    <br>
                    Color Range: Narrow Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-narrow.png" height="210" width="360">
                    <br>
                    Color Range: Original Wide
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-wide.png" height="210" width="360">
                    <br>
                    Color Range: Original Catered
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-color.png" height="210" width="360">
                    <br>
                    Color Range: Original Narrow
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-narrow.png" height="210" width="360">
                    <br>
                </div>
                <div class="col">
                    Dilate: 20x20 kernel Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-morph-high.png" height="210" width="360">
                    <br> 
                    Dilate: 10x10 kernel Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-morph-good.png" height="210" width="360">
                    <br>
                    Dilate: 2x2 kernel Cropped
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-morph-low.png" height="210" width="360">
                    <br>
                    Dilate: Original 20x20 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-high.png" height="210" width="360">
                    <br> 
                    Dilate: Original 10x10 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-color.png" height="210" width="360">
                    <br>
                    Dilate: Original 2x2 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/aqua-nocrop-low.png" height="210" width="360">
                    <br>
                </div>
            </p>
            <p>
                <span class="sub-header">Bats Dataset: Morphological Operations Experiment
                <div class="col">
                    Segmented
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-seg.png" height="210" width="360">
                    <br> 
                    Erode: 1x1 kernel, Dilate: 1x1 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morphed.png" height="210" width="360">
                    <br>
                    Labeled/Colored
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morph-good.png" height="210" width="360">
                    <br>
                </div>
                <div class="col">
                    Dilate: 20x20 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morph-high.png" height="210" width="360">
                    <br> 
                    Dilate: 10x10 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morph-good.png" height="210" width="360">
                    <br>
                    Dilate: 2x2 kernel
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morph-low.png" height="210" width="360">
                    <br>
                </div>
                <div class="col">
                    Fragmented object (gray/orange, center)
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morph-good-imperf.png" height="210" width="360">
                    <br> 
                    Inextricable objects (two red bats, center)
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morph-good-imperf2.png" height="210" width="360">
                    Twins (two green bats, center)
                    <br>
                    <img src="/chenjus/cs585/a3/imgs/bat-morph-twins.png" height="210" width="360">
                    <br>
                </div>
            </p>
            <p>
                <span class="sub-header">Discussion</span>
                <br> 
                <p>
                Each algorithm had it's strengths and weaknesses. Absolute thresholding with background differencing worked very well for segmenting cells because the cells sporadically moved between frames making them easy to detect. This method was also very easy to implement. However, this method is not suitable for videos where objects do not move very much in videos. Color range selection works very well when the color of the object that you want to segment is known beforehand. For detecting fish in the aquarium, there were very few attributes to segment with. Since most of the fish were within a certain range of colors, this worked reasonably. However, it was not perfect and still unintendedly captured background objects. Iterative thresholding worked very well for the bats dataset. The background highly constrasted with the bats making them easy to segment out. However, iterative thresholding only works well if the objects have a consistent color like the bats, which were all originally white and the background was mostly black.
                </p>
                <p>
                As for the analysis of each object in each frame, each property varied in usefulness depending on the image. Orientation only has meaning if the object has a clear top and bottom. However, the top and bottom of the cells, bats, and the fish could not be clearly depicted after segmentation, so this had little meaning in terms of determining how these objects were oriented. However, orientation, specifically for cells, indicated the direction they were moving. As the cells moved, they elongate towards the direction they travel and then contract when they reach that point. Orientation is useful for determining the direction and distance cells moves. It is also useful for determining the direction of a bat's flight, right, negative orientation value, or left, position orientation value. As for circularity, this is useful for determining if a bat's wings are expanded or if they're folded. Circularity can also be used to determine if a cell is moving. Area is useful for determining if a bat is moving closer or farther from the camera. A larger area means it's closer and a smaller area means it's farther away. This property also applies to fish, however, they did not move much in the z-axis in the given video. Compactness is useful for determining clusters of objects. This can be useful for following a school of fish or a group of bats traveling together or for determining how cells interact with each other.
                </p>
                <p>
                Overall, my methods were successful in segmenting and labeling individual objects in each video. I expected that it would be reasonably easy to segment out the bats, and cells, but not the fish. As I expected, it was hard to segment out the fish and was easy to find the bats and cells.
                </p>
                If I had more time, more work could have been done to consistently track cells and bats from frame to frame, so if a bat was labeled red in the first frame, it could be labeled red throughout the entire video and each bat would be a different color. More work could also be done to improve segmenting the fish. However, I cannot immediately think of any obvious solutions.
                <p>
            </p>
            <p>
                <span class="sub-header">Conclusions</span>
                <br> In conclusion, the choice of segmentation method depends on quality of the images and the objects in the images. In turn, analyzing the properties of each object depends on how well the objects can be labeled, which depends on how well the objects can be segmented.
            </p>
            <p>
                <span class="sub-header">Credits and Bibliography</span>
                <br> 
                <a target="_blank" href="http://docs.opencv.org/doc/tutorials/introduction/load_save_image/load_save_image.html">http://docs.opencv.org/doc/tutorials/introduction/load_save_image/load_save_image.html</a><br> 
                <a target="_blank" href="http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html">http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html</a><br>  
                <a target="_blank" href="http://docs.opencv.org/modules/core/doc/basic_structures.html?highlight=mat#mat-zeros">http://docs.opencv.org/modules/core/doc/basic_structures.html?highlight=mat#mat-zeros</a><br> 
                <a target="_blank" href="http://ninghang.blogspot.com/2012/11/list-of-mat-type-in-opencv.html">http://ninghang.blogspot.com/2012/11/list-of-mat-type-in-opencv.html</a><br> 
                <a target="_blank" href="http://docs.opencv.org/modules/core/doc/basic_structures.html#mat-clone">http://docs.opencv.org/modules/core/doc/basic_structures.html#mat-clone</a><br> 
                <a target="_blank" href="http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=cvtcolor#cvtcolor">http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=cvtcolor#cvtcolor</a><br> 
                <a target="_blank" href="http://docs.opencv.org/modules/imgproc/doc/filtering.html">http://docs.opencv.org/modules/imgproc/doc/filtering.html</a><br> 
                <a target="_blank" href="http://www.cplusplus.com/reference/queue/queue/">http://www.cplusplus.com/reference/queue/queue/</a><br> 
            </p>
        </div>
    </div>
</body>
<footer>
</footer>

</html>
